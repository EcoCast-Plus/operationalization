name: Daily Ocean Predictions

on:
  # schedule:
  # - cron: '30 15 * * *' # 3:30 PM UTC daily
  workflow_dispatch:

permissions:
  contents: write

jobs:
  # ----------------------------------------------------------------
  # JOB 1: DOWNLOAD ALL DATA (Surface + Deep)
  # ----------------------------------------------------------------
  download_cmems:
    runs-on: ubuntu-latest
    env:
      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
      COPERNICUSMARINE_SERVICE_USERNAME: ${{ secrets.COPERNICUSMARINE_SERVICE_USERNAME }}
      COPERNICUSMARINE_SERVICE_PASSWORD: ${{ secrets.COPERNICUSMARINE_SERVICE_PASSWORD }}
    steps:
    # 1. CLEAN SYSTEM BLOAT (Make room for the job)
    - name: Free Disk Space
      run: |
        sudo rm -rf /usr/share/dotnet
        sudo rm -rf /usr/local/lib/android
        sudo rm -rf /opt/ghc

    - name: Check out repository
      uses: actions/checkout@v4

    - name: Install Conda & Capture Tool Path
      uses: conda-incubator/setup-miniconda@v3
      with:
        auto-update-conda: true
        python-version: 3.11
        activate-environment: test

    - name: Install Copernicus Tool
      shell: bash -el {0}
      run: |
        conda install -c conda-forge copernicusmarine scipy
        # Capture Path for R
        TOOL_PATH=$(which copernicusmarine)
        echo "CM_TOOL_PATH=$TOOL_PATH" >> $GITHUB_ENV

    - name: Install R
      uses: r-lib/actions/setup-r@v2
      with:
        r-version: '4.4.3'

    - name: Install R Packages
      uses: r-lib/actions/setup-r-dependencies@v2
      with:
        cache: always
        packages: |
          any::readr 
          any::dplyr 
          any::glue 
          any::purrr 
          any::httr       # Required for GitHub API calls
          any::jsonlite   # Required for parsing API response
          any::lubridate  # Required for date math
          any::stringr    # Required for regex
          any::gh         # Good practice for GH interactions

    # 2. CLEAN OLD PROJECT FILES (Your script)
    - name: Delete Old CMEMS Data
      shell: Rscript {0}
      run: |
        if (file.exists("repo_cleanup/delete_old_files.R")) {
          source("repo_cleanup/delete_old_files.R")
        } else {
          message("Cleanup script not found, skipping.")
        }

    - name: Run Download Script
      shell: Rscript {0}
      run: source("data_acquisition/R/acquire_cmems.R")

    # Pass the raw NetCDFs to the next jobs
    - name: Upload Raw Data Artifact
      uses: actions/upload-artifact@v4
      with:
        name: raw_cmems
        path: data_acquisition/netcdfs/cmems_ncdfs/
        retention-days: 1

    - name: Commit New Raw Files
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        git add data_acquisition/netcdfs/cmems_ncdfs/
        git diff --staged --quiet || (git commit -m "Added raw CMEMS files" && git pull --rebase && git push)

  # ----------------------------------------------------------------
  # JOB 2: PROCESS STANDARD DATA (Top Predator Watch)
  # ----------------------------------------------------------------
  process_cmems:
    needs: download_cmems
    runs-on: ubuntu-latest
    env:
      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
    steps:
    - uses: actions/checkout@v4
    
    - name: Download Raw Data
      uses: actions/download-artifact@v4
      with:
        name: raw_cmems
        path: data_acquisition/netcdfs/cmems_ncdfs/

    - uses: r-lib/actions/setup-r@v2
      with: { r-version: '4.4.3' }
      
    - uses: r-lib/actions/setup-r-dependencies@v2
      with:
        cache: always
        packages: any::terra any::dplyr any::glue any::purrr any::readr any::lubridate

    - name: Run Standard Processing
      shell: Rscript {0}
      run: source("data_processing/R/process_cmems.R")

    # Pass the processed TIFFs to the prediction jobs
    - name: Upload Processed TIFFs Artifact
      uses: actions/upload-artifact@v4
      with:
        name: processed_tiffs
        path: data_processing/TopPredatorWatch/rasters/
        retention-days: 1

    - name: Commit Processed Files
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        git add data_processing/TopPredatorWatch/rasters/
        git diff --staged --quiet || (git commit -m "Processed CMEMS files" && git pull --rebase && git push)

  # ----------------------------------------------------------------
  # JOB 3: PREDICT TOP PREDATOR (Colleague's Model)
  # ----------------------------------------------------------------
  predict_top_pred:
    needs: process_cmems
    runs-on: ubuntu-latest
    env:
      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
    steps:
    - uses: actions/checkout@v4

    - name: Download Processed TIFFs
      uses: actions/download-artifact@v4
      with:
        name: processed_tiffs
        path: data_processing/TopPredatorWatch/rasters/

    - uses: r-lib/actions/setup-r@v2
      with: { r-version: '4.4.3' }

    - uses: r-lib/actions/setup-r-dependencies@v2
      with:
        cache: always
        packages: |
          any::remotes
          any::sf
          any::terra
          any::tidyverse
          any::glue
          any::gbm
          any::rnaturalearth
          any::pals

    - name: Install rnaturalearthhires
      shell: Rscript {0}
      run: remotes::install_github("ropensci/rnaturalearthhires")

    - name: Run TopPred Prediction
      shell: Rscript {0}
      run: source("model_prediction/R/predict_TopPredatorWatch.R")

    - name: Commit TopPred Results
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        git add model_prediction/TopPredatorWatch/
        git diff --staged --quiet || (git commit -m "TopPred predictions" && git pull --rebase && git push)

  # ----------------------------------------------------------------
  # JOB 4: PREDICT GULF (Your New Model)
  # ----------------------------------------------------------------
  # predict_gulf:
  #   needs: [download_cmems, process_cmems]
  #   runs-on: ubuntu-latest
  #   env:
  #     GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
  #   steps:
  #   - uses: actions/checkout@v4

  #   # Get RAW NetCDFs (for deep variables)
  #   - name: Download Raw Data
  #     uses: actions/download-artifact@v4
  #     with:
  #       name: raw_cmems
  #       path: data_acquisition/netcdfs/cmems_ncdfs/

  #   # Get PROCESSED TIFFs (for surface variables)
  #   - name: Download Processed Data
  #     uses: actions/download-artifact@v4
  #     with:
  #       name: processed_tiffs
  #       path: data_processing/TopPredatorWatch/rasters/

  #   - uses: r-lib/actions/setup-r@v2
  #     with: { r-version: '4.4.3' }

  #   - uses: r-lib/actions/setup-r-dependencies@v2
  #     with:
  #       cache: always
  #       packages: |
  #         any::tidysdm
  #         any::tidyverse
  #         any::sf
  #         any::terra
  #         any::lubridate
  #         any::oce
  #         any::grec
  #         any::bundle
  #         any::xgboost
  #         any::ranger
  #         any::mgcv
  #         any::glue

  #   - name: Run Gulf Prediction
  #     shell: Rscript {0}
  #     run: source("model_prediction/R/predict_gulf.R")

  #   - name: Commit Gulf Results
  #     run: |
  #       git config --global user.name "GitHub Actions"
  #       git config --global user.email "actions@github.com"
  #       git add app/data/latest_predictions.rds
  #       git diff --staged --quiet || (git commit -m "Gulf predictions" && git pull --rebase && git push)
